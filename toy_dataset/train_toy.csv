diff,msg,repo,sha,time
diff - - git a / XSS Injection / README . md b / XSS Injection / README . md <nl> mmm a / XSS Injection / README . md <nl> ppp b / XSS Injection / README . md <nl> More exploits at [ http : / / www . xss - payloads . com / payloads - list . html ? a # category = all ] <nl> ` ` ` <nl> <nl> # # # Tools <nl> + <nl> + Most tools are also suitable for blind XSS attacks : <nl> + <nl> * [ XSSStrike ] ( https : / / github . com / s0md3v / XSStrike ) : Very popular but unfortunately not very well maintained <nl> * [ xsser ] ( https : / / github . com / epsylon / xsser ) : Utilizes a headless browser to detect XSS vulnerabilities <nl> * [ Dalfox ] ( https : / / github . com / hahwul / dalfox ) : Extensive functionality and extremely fast thanks to the implementation in Go <nl> * [ XSpear ] ( https : / / github . com / hahwul / XSpear ) : Similar to Dalfox but based on Ruby <nl> - * [ domdig ] ( git @ github . com : fcavallarin / domdig . git ) : Headless Chrome XSS Tester <nl> + * [ domdig ] ( https : / / github . com / fcavallarin / domdig ) : Headless Chrome XSS Tester <nl> <nl> # # XSS in HTML / Applications <nl> <nl>,little update,swisskyrepo/PayloadsAllTheThings,2a65064d15379a6eceba9627c5e7623dc505a773,2020-10-27T13:10:35Z
"mmm a / Lib / inspect . py <nl> ppp b / Lib / inspect . py <nl> def getfullargspec ( func ) : <nl> "" "" "" <nl> <nl> warnings . warn ( "" Use inspect . signature ( ) instead of inspect . getfullargspec ( ) "" , <nl> - DeprecationWarning ) <nl> + DeprecationWarning , stacklevel = 2 ) <nl> try : <nl> # Re : ` skip_bound_arg = False ` <nl> # <nl>",MNT : set stacklevel in the getfullargspec deprecation warning to 2 ( GH - 13029 ),python/cpython,18029d80bde1743da6900600633f0fa54d7c1044,2019-05-01T15:12:34Z
"mmm a / . github / BOTMETA . yml <nl> ppp b / . github / BOTMETA . yml <nl> macros : <nl> team_bsd : AMDmi3 bcoca dagwieers jasperla JoergFiedler mekanix opoplawski overhacked tuxillo <nl> team_cloudscale : gaudenz resmo <nl> team_cloudstack : resmo dpassante rhtyd <nl> - team_crypto : felixfontein resmo spredzy <nl> + team_crypto : felixfontein resmo Spredzy <nl> team_cumulus : isharacomix jrrivers <nl> team_cyberark_conjur : jvanderhoof ryanprior <nl> team_digital_ocean : aluvenko , BondAnthony , mgregson <nl>",BOTMETA : Fix Spredzy ' s case ( ),ansible/ansible,339658dee251faf1c0fedfd4e552aac5956b1d85,2019-02-11T09:33:22Z
"mmm a / pipenv / patched / patched . txt <nl> ppp b / pipenv / patched / patched . txt <nl> git + https : / / github . com / jumpscale7 / python - consistent - toml . git # egg = contoml <nl> crayons = = 0 . 1 . 2 <nl> git + https : / / github . com / berdario / pew . git @ 1 . 1 . 5 # egg = pew <nl> pipfile = = 0 . 0 . 2 <nl> - pip - tools = = 2 . 0 . 1 <nl> + git + https : / / github . com / jazzband / pip - tools . git @ 9cb41d828fcb0967a32cc140c1dcaca94e5f4daa # egg = piptools <nl> prettytoml = = 0 . 3 <nl> pip = = 9 . 0 . 3 <nl> new file mode 100644 <nl> index 000000000 . . 89de35479 <nl> mmm / dev / null <nl> ppp b / pipenv / patched / piptools / LICENSE . txt <nl> <nl> + Permission is hereby granted , free of charge , to any person obtaining a copy <nl> + of this software and associated documentation files ( the "" Software "" ) , to deal <nl> + in the Software without restriction , including without limitation the rights <nl> + to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> + copies of the Software , and to permit persons to whom the Software is <nl> + furnished to do so , subject to the following conditions : <nl> + <nl> + The above copyright notice and this permission notice shall be included in <nl> + all copies or substantial portions of the Software . <nl> + <nl> + THE SOFTWARE IS PROVIDED "" AS IS "" , WITHOUT WARRANTY OF ANY KIND , EXPRESS OR <nl> + IMPLIED , INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY , <nl> + FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT . IN NO EVENT SHALL THE <nl> + AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM , DAMAGES OR OTHER <nl> + LIABILITY , WHETHER IN AN ACTION OF CONTRACT , TORT OR OTHERWISE , ARISING FROM , <nl> + OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN <nl> + THE SOFTWARE . <nl> mmm a / pipenv / patched / piptools / __init__ . py <nl> ppp b / pipenv / patched / piptools / __init__ . py <nl> <nl> - import os <nl> - import sys <nl> - <nl> - # Inject vendored directory into system path . <nl> - v_path = os . path . abspath ( os . path . sep . join ( [ os . path . dirname ( os . path . realpath ( __file__ ) ) , ' _vendored ' ] ) ) <nl> - sys . path . insert ( 0 , v_path ) <nl> mmm a / pipenv / patched / piptools / _compat / __init__ . py <nl> ppp b / pipenv / patched / piptools / _compat / __init__ . py <nl> <nl> else : <nl> from tempfile import TemporaryDirectory <nl> from contextlib import ExitStack <nl> + <nl> + from . pip_compat import ( <nl> + InstallRequirement , <nl> + parse_requirements , <nl> + RequirementSet , <nl> + user_cache_dir , <nl> + FAVORITE_HASH , <nl> + is_file_url , <nl> + url_to_path , <nl> + PackageFinder , <nl> + FormatControl , <nl> + Wheel , <nl> + Command , <nl> + cmdoptions , <nl> + get_installed_distributions , <nl> + PyPI , <nl> + SafeFileCache , <nl> + ) <nl> new file mode 100644 <nl> index 000000000 . . 96c8a1eac <nl> mmm / dev / null <nl> ppp b / pipenv / patched / piptools / _compat / pip_compat . py <nl> <nl> + # - * - coding = utf - 8 - * - <nl> + import importlib <nl> + <nl> + <nl> + def do_import ( module_path , subimport = None , old_path = None , vendored_name = None ) : <nl> + internal = ' pip . _internal . { 0 } ' . format ( module_path ) <nl> + old_path = old_path or module_path <nl> + pip9 = ' pip . { 0 } ' . format ( old_path ) <nl> + _tmp = None <nl> + if vendored_name : <nl> + vendor = ' { 0 } . { 1 } ' . format ( vendored_name , old_path ) <nl> + try : <nl> + _tmp = importlib . import_module ( vendor ) <nl> + except ImportError : <nl> + pass <nl> + if not _tmp : <nl> + try : <nl> + _tmp = importlib . import_module ( internal ) <nl> + except ImportError : <nl> + _tmp = importlib . import_module ( pip9 ) <nl> + if subimport : <nl> + return getattr ( _tmp , subimport , _tmp ) <nl> + return _tmp <nl> + <nl> + <nl> + InstallRequirement = do_import ( ' req . req_install ' , ' InstallRequirement ' , vendored_name = ' notpip ' ) <nl> + parse_requirements = do_import ( ' req . req_file ' , ' parse_requirements ' , vendored_name = ' notpip ' ) <nl> + RequirementSet = do_import ( ' req . req_set ' , ' RequirementSet ' , vendored_name = ' notpip ' ) <nl> + user_cache_dir = do_import ( ' utils . appdirs ' , ' user_cache_dir ' , vendored_name = ' notpip ' ) <nl> + FAVORITE_HASH = do_import ( ' utils . hashes ' , ' FAVORITE_HASH ' , vendored_name = ' notpip ' ) <nl> + is_file_url = do_import ( ' download ' , ' is_file_url ' , vendored_name = ' notpip ' ) <nl> + url_to_path = do_import ( ' download ' , ' url_to_path ' , vendored_name = ' notpip ' ) <nl> + PackageFinder = do_import ( ' index ' , ' PackageFinder ' , vendored_name = ' notpip ' ) <nl> + FormatControl = do_import ( ' index ' , ' FormatControl ' , vendored_name = ' notpip ' ) <nl> + Wheel = do_import ( ' wheel ' , ' Wheel ' , vendored_name = ' notpip ' ) <nl> + Command = do_import ( ' basecommand ' , ' Command ' , vendored_name = ' pip9 ' ) <nl> + cmdoptions = do_import ( ' cmdoptions ' , vendored_name = ' pip9 ' ) <nl> + get_installed_distributions = do_import ( ' utils . misc ' , ' get_installed_distributions ' , old_path = ' utils ' , vendored_name = ' pip9 ' ) <nl> + PyPI = do_import ( ' models . index ' , ' PyPI ' , vendored_name = ' notpip ' ) <nl> + SafeFileCache = do_import ( ' download ' , ' SafeFileCache ' , vendored_name = ' notpip ' ) <nl> mmm a / pipenv / patched / piptools / cache . py <nl> ppp b / pipenv / patched / piptools / cache . py <nl> <nl> import os <nl> import sys <nl> <nl> - from pip9 . _vendor . packaging . requirements import Requirement <nl> + from pip . _vendor . packaging . requirements import Requirement <nl> <nl> from . exceptions import PipToolsError <nl> from . locations import CACHE_DIR <nl> mmm a / pipenv / patched / piptools / exceptions . py <nl> ppp b / pipenv / patched / piptools / exceptions . py <nl> class PipToolsError ( Exception ) : <nl> <nl> <nl> class NoCandidateFound ( PipToolsError ) : <nl> - def __init__ ( self , ireq , candidates_tried , index_urls ) : <nl> + def __init__ ( self , ireq , candidates_tried , finder ) : <nl> self . ireq = ireq <nl> self . candidates_tried = candidates_tried <nl> - self . index_urls = index_urls <nl> + self . finder = finder <nl> <nl> def __str__ ( self ) : <nl> - sorted_versions = sorted ( c . version for c in self . candidates_tried ) <nl> + versions = [ ] <nl> + pre_versions = [ ] <nl> + <nl> + for candidate in sorted ( self . candidates_tried ) : <nl> + version = str ( candidate . version ) <nl> + if candidate . version . is_prerelease : <nl> + pre_versions . append ( version ) <nl> + else : <nl> + versions . append ( version ) <nl> + <nl> lines = [ <nl> ' Could not find a version that matches { } ' . format ( self . ireq ) , <nl> - ' Tried : { } ' . format ( ' , ' . join ( str ( version ) for version in sorted_versions ) or ' ( no version found at all ) ' ) <nl> ] <nl> - if sorted_versions : <nl> + <nl> + if versions : <nl> + lines . append ( ' Tried : { } ' . format ( ' , ' . join ( versions ) ) ) <nl> + <nl> + if pre_versions : <nl> + if self . finder . allow_all_prereleases : <nl> + line = ' Tried ' <nl> + else : <nl> + line = ' Skipped ' <nl> + <nl> + line + = ' pre - versions : { } ' . format ( ' , ' . join ( pre_versions ) ) <nl> + lines . append ( line ) <nl> + <nl> + if versions or pre_versions : <nl> lines . append ( ' There are incompatible versions in the resolved dependencies . ' ) <nl> else : <nl> + lines . append ( ' No versions found ' ) <nl> lines . append ( ' { } { } reachable ? ' . format ( <nl> - ' Were ' if len ( self . index_urls ) > 1 else ' Was ' , ' or ' . join ( self . index_urls ) ) <nl> + ' Were ' if len ( self . finder . index_urls ) > 1 else ' Was ' , ' or ' . join ( self . finder . index_urls ) ) <nl> ) <nl> return ' \ n ' . join ( lines ) <nl> <nl> mmm a / pipenv / patched / piptools / locations . py <nl> ppp b / pipenv / patched / piptools / locations . py <nl> <nl> <nl> from . click import secho <nl> # Patch by vphilippon 2017 - 11 - 22 : Use pipenv cache path . <nl> - # from pip9 . utils . appdirs import user_cache_dir <nl> + # from . _compat import user_cache_dir <nl> from pipenv . environments import PIPENV_CACHE_DIR <nl> <nl> # The user_cache_dir helper comes straight from pip itself <nl> mmm a / pipenv / patched / piptools / repositories / base . py <nl> ppp b / pipenv / patched / piptools / repositories / base . py <nl> def get_hashes ( self , ireq ) : <nl> @ contextmanager <nl> def allow_all_wheels ( self ) : <nl> "" "" "" <nl> - Monkey patches pip9 . Wheel to allow wheels from all platforms and Python versions . <nl> + Monkey patches pip . Wheel to allow wheels from all platforms and Python versions . <nl> "" "" "" <nl> mmm a / pipenv / patched / piptools / repositories / local . py <nl> ppp b / pipenv / patched / piptools / repositories / local . py <nl> <nl> <nl> from piptools . utils import as_tuple , key_from_req , make_install_requirement <nl> from . base import BaseRepository <nl> - from pip9 . utils . hashes import FAVORITE_HASH <nl> + from . . _compat import FAVORITE_HASH <nl> <nl> <nl> def ireq_satisfied_by_existing_pin ( ireq , existing_pin ) : <nl> mmm a / pipenv / patched / piptools / repositories / pypi . py <nl> ppp b / pipenv / patched / piptools / repositories / pypi . py <nl> <nl> from contextlib import contextmanager <nl> from shutil import rmtree <nl> <nl> - from notpip . download import is_file_url , url_to_path <nl> - from notpip . index import PackageFinder <nl> - from notpip . req . req_set import RequirementSet <nl> - from notpip . wheel import Wheel <nl> - from notpip . req . req_install import InstallRequirement <nl> + from . . _compat import ( <nl> + is_file_url , <nl> + url_to_path , <nl> + PackageFinder , <nl> + RequirementSet , <nl> + Wheel , <nl> + FAVORITE_HASH , <nl> + TemporaryDirectory , <nl> + PyPI , <nl> + InstallRequirement , <nl> + SafeFileCache , <nl> + ) <nl> + <nl> from pip9 . _vendor . packaging . requirements import InvalidRequirement <nl> from pip9 . _vendor . pyparsing import ParseException <nl> - from notpip . download import SafeFileCache <nl> - from notpip . utils . hashes import FAVORITE_HASH <nl> <nl> - from . . _compat import TemporaryDirectory <nl> from . . cache import CACHE_DIR <nl> from pipenv . environments import PIPENV_CACHE_DIR <nl> from . . exceptions import NoCandidateFound <nl> <nl> from . base import BaseRepository <nl> <nl> <nl> + try : <nl> + from pip . _internal . operations . prepare import RequirementPreparer <nl> + from pip . _internal . resolve import Resolver as PipResolver <nl> + except ImportError : <nl> + pass <nl> + <nl> + try : <nl> + from pip . _internal . cache import WheelCache <nl> + except ImportError : <nl> + from pip . wheel import WheelCache <nl> + <nl> + <nl> class HashCache ( SafeFileCache ) : <nl> "" "" "" Caches hashes of PyPI artifacts so we do not need to re - download them <nl> <nl> - Hashes are only cached when the URL appears to contain a hash in it ( and the cache key includes <nl> - the hash value returned from the server ) . This ought to avoid issues where the location on the <nl> + Hashes are only cached when the URL appears to contain a hash in it and the cache key includes <nl> + the hash value returned from the server ) . This ought to avoid ssues where the location on the <nl> server changes . "" "" "" <nl> def __init__ ( self , * args , * * kwargs ) : <nl> session = kwargs . pop ( ' session ' ) <nl> def __init__ ( self , * args , * * kwargs ) : <nl> super ( HashCache , self ) . __init__ ( * args , * * kwargs ) <nl> <nl> def get_hash ( self , location ) : <nl> - # if there is no location hash ( i . e . , md5 / sha256 / etc ) we don ' t want to store it <nl> + # if there is no location hash ( i . e . , md5 / sha256 / etc ) we on ' t want to store it <nl> hash_value = None <nl> can_hash = location . hash <nl> if can_hash : <nl> def _get_file_hash ( self , location ) : <nl> <nl> <nl> class PyPIRepository ( BaseRepository ) : <nl> - DEFAULT_INDEX_URL = ' https : / / pypi . org / simple ' <nl> + DEFAULT_INDEX_URL = PyPI . simple_url <nl> <nl> "" "" "" <nl> The PyPIRepository will use the provided Finder instance to lookup <nl> class PyPIRepository ( BaseRepository ) : <nl> def __init__ ( self , pip_options , session , use_json = False ) : <nl> self . session = session <nl> self . use_json = use_json <nl> + self . pip_options = pip_options <nl> + self . wheel_cache = WheelCache ( PIPENV_CACHE_DIR , pip_options . format_control ) <nl> <nl> index_urls = [ pip_options . index_url ] + pip_options . extra_index_urls <nl> if pip_options . no_index : <nl> def __init__ ( self , pip_options , session , use_json = False ) : <nl> <nl> # Setup file paths <nl> self . freshen_build_caches ( ) <nl> - self . _download_dir = fs_str ( os . path . join ( CACHE_DIR , ' pkgs ' ) ) <nl> - self . _wheel_download_dir = fs_str ( os . path . join ( CACHE_DIR , ' wheels ' ) ) <nl> + self . _download_dir = fs_str ( os . path . join ( PIPENV_CACHE_DIR , ' pkgs ' ) ) <nl> + self . _wheel_download_dir = fs_str ( os . path . join ( PIPENV_CACHE_DIR , ' wheels ' ) ) <nl> <nl> def freshen_build_caches ( self ) : <nl> "" "" "" <nl> def find_best_match ( self , ireq , prereleases = None ) : <nl> # Reuses pip ' s internal candidate sort key to sort <nl> matching_candidates = [ candidates_by_version [ ver ] for ver in matching_versions ] <nl> if not matching_candidates : <nl> - raise NoCandidateFound ( ireq , all_candidates , self . finder . index_urls ) <nl> + raise NoCandidateFound ( ireq , all_candidates , self . finder ) <nl> best_candidate = max ( matching_candidates , key = self . finder . _candidate_sort_key ) <nl> <nl> # Turn the candidate into a pinned InstallRequirement <nl> def gen ( ireq ) : <nl> # TODO : Latest isn ' t always latest . <nl> latest = list ( r . json ( ) [ ' releases ' ] . keys ( ) ) [ - 1 ] <nl> if str ( ireq . req . specifier ) = = ' = = { 0 } ' . format ( latest ) : <nl> - <nl> - for requires in r . json ( ) . get ( ' info ' , { } ) . get ( ' requires_dist ' , { } ) : <nl> + latest_url = ' https : / / pypi . org / pypi / { 0 } / { 1 } / json ' . format ( ireq . req . name , latest ) <nl> + latest_requires = self . session . get ( latest_url ) <nl> + for requires in latest_requires . json ( ) . get ( ' info ' , { } ) . get ( ' requires_dist ' , { } ) : <nl> i = InstallRequirement . from_line ( requires ) <nl> <nl> if ' extra ' not in repr ( i . markers ) : <nl> def gen ( ireq ) : <nl> except Exception : <nl> return set ( ) <nl> <nl> - <nl> def get_dependencies ( self , ireq ) : <nl> json_results = set ( ) <nl> <nl> def get_legacy_dependencies ( self , ireq ) : <nl> except TypeError : <nl> pass <nl> <nl> - <nl> if ireq not in self . _dependencies_cache : <nl> if ireq . editable and ( ireq . source_dir and os . path . exists ( ireq . source_dir ) ) : <nl> # No download_dir for locally available editable requirements . <nl> def get_legacy_dependencies ( self , ireq ) : <nl> if not os . path . isdir ( self . _wheel_download_dir ) : <nl> os . makedirs ( self . _wheel_download_dir ) <nl> <nl> - reqset = RequirementSet ( self . build_dir , <nl> - self . source_dir , <nl> - download_dir = download_dir , <nl> - wheel_download_dir = self . _wheel_download_dir , <nl> - session = self . session , <nl> - ignore_installed = True , <nl> - ignore_compatibility = False <nl> - ) <nl> - <nl> - result = reqset . _prepare_file ( self . finder , ireq , ignore_requires_python = True ) <nl> - <nl> + try : <nl> + # Pip < 9 and below <nl> + reqset = RequirementSet ( <nl> + self . build_dir , <nl> + self . source_dir , <nl> + download_dir = download_dir , <nl> + wheel_download_dir = self . _wheel_download_dir , <nl> + session = self . session , <nl> + ignore_installed = True , <nl> + ignore_compatibility = False , <nl> + wheel_cache = self . wheel_cache , <nl> + ) <nl> + result = reqset . _prepare_file ( <nl> + self . finder , <nl> + ireq , <nl> + ignore_requires_python = True <nl> + ) <nl> + except TypeError : <nl> + # Pip > = 10 ( new resolver ! ) <nl> + preparer = RequirementPreparer ( <nl> + build_dir = self . build_dir , <nl> + src_dir = self . source_dir , <nl> + download_dir = download_dir , <nl> + wheel_download_dir = self . _wheel_download_dir , <nl> + progress_bar = ' off ' , <nl> + build_isolation = False <nl> + ) <nl> + reqset = RequirementSet ( ) <nl> + ireq . is_direct = True <nl> + reqset . add_requirement ( ireq ) <nl> + self . resolver = PipResolver ( <nl> + preparer = preparer , <nl> + finder = self . finder , <nl> + session = self . session , <nl> + upgrade_strategy = "" to - satisfy - only "" , <nl> + force_reinstall = False , <nl> + ignore_dependencies = False , <nl> + ignore_requires_python = False , <nl> + ignore_installed = True , <nl> + isolated = False , <nl> + wheel_cache = self . wheel_cache , <nl> + use_user_site = False , <nl> + ignore_compatibility = False <nl> + ) <nl> + self . resolver . resolve ( reqset ) <nl> + result = reqset . requirements . values ( ) <nl> # Convert setup_requires dict into a somewhat usable form . <nl> if setup_requires : <nl> for section in setup_requires : <nl> def get_legacy_dependencies ( self , ireq ) : <nl> pass <nl> <nl> if reqset . requires_python : <nl> - <nl> marker = ' python_version = = "" { 0 } "" ' . format ( reqset . requires_python . replace ( ' ' , ' ' ) ) <nl> new_req = InstallRequirement . from_line ( ' { 0 } ; { 1 } ' . format ( str ( ireq . req ) , marker ) ) <nl> result = [ new_req ] <nl> <nl> self . _dependencies_cache [ ireq ] = result <nl> + reqset . cleanup_files ( ) <nl> return set ( self . _dependencies_cache [ ireq ] ) <nl> <nl> def get_hashes ( self , ireq ) : <nl> def get_hashes ( self , ireq ) : <nl> @ contextmanager <nl> def allow_all_wheels ( self ) : <nl> "" "" "" <nl> - Monkey patches pip9 . Wheel to allow wheels from all platforms and Python versions . <nl> + Monkey patches pip . Wheel to allow wheels from all platforms and Python versions . <nl> <nl> This also saves the candidate cache and set a new one , or else the results from the <nl> previous non - patched calls will interfere . <nl> def open_local_or_remote_file ( link , session ) : <nl> "" "" "" <nl> Open local or remote file for reading . <nl> <nl> - : type link : pip9 . index . Link <nl> + : type link : pip . index . Link <nl> : type session : requests . Session <nl> : raises ValueError : If link points to a local directory . <nl> : return : a context manager to the opened file - like object <nl> mmm a / pipenv / patched / piptools / resolver . py <nl> ppp b / pipenv / patched / piptools / resolver . py <nl> <nl> import os <nl> <nl> from first import first <nl> - from pip9 . req import InstallRequirement <nl> + from . _compat import InstallRequirement <nl> <nl> from . import click <nl> from . cache import DependencyCache <nl> def _iter_dependencies ( self , ireq ) : <nl> dependency_strings = self . dependency_cache [ ireq ] <nl> log . debug ( ' { : 25 } requires { } ' . format ( format_requirement ( ireq ) , <nl> ' , ' . join ( sorted ( dependency_strings , key = lambda s : s . lower ( ) ) ) or ' - ' ) ) <nl> - from notpip . _vendor . packaging . markers import InvalidMarker <nl> + from pip9 . _vendor . packaging . markers import InvalidMarker <nl> for dependency_string in dependency_strings : <nl> try : <nl> _dependency_string = dependency_string <nl> def _iter_dependencies ( self , ireq ) : <nl> except InvalidMarker : <nl> yield InstallRequirement . from_line ( dependency_string , constraint = ireq . constraint ) <nl> <nl> - <nl> def reverse_dependencies ( self , ireqs ) : <nl> non_editable = [ ireq for ireq in ireqs if not ireq . editable ] <nl> return self . dependency_cache . reverse_dependencies ( non_editable ) <nl> mmm a / pipenv / patched / piptools / scripts / compile . py <nl> ppp b / pipenv / patched / piptools / scripts / compile . py <nl> <nl> import sys <nl> import tempfile <nl> <nl> - import pip9 <nl> - from pip9 . req import InstallRequirement , parse_requirements <nl> + from . . _compat import ( <nl> + InstallRequirement , <nl> + parse_requirements , <nl> + cmdoptions , <nl> + Command , <nl> + ) <nl> <nl> from . . import click <nl> from . . exceptions import PipToolsError <nl> <nl> DEFAULT_REQUIREMENTS_FILE = ' requirements . in ' <nl> <nl> <nl> - class PipCommand ( pip9 . basecommand . Command ) : <nl> + class PipCommand ( Command ) : <nl> name = ' PipCommand ' <nl> <nl> <nl> def cli ( verbose , dry_run , pre , rebuild , find_links , index_url , extra_index_url , <nl> <nl> <nl> def get_pip_command ( ) : <nl> - # Use pip ' s parser for pip9 . conf management and defaults . <nl> + # Use pip ' s parser for pip . conf management and defaults . <nl> # General options ( find_links , index_url , extra_index_url , trusted_host , <nl> - # and pre ) are defered to pip9 . <nl> + # and pre ) are defered to pip . <nl> pip_command = PipCommand ( ) <nl> - index_opts = pip9 . cmdoptions . make_option_group ( <nl> - pip9 . cmdoptions . index_group , <nl> + pip_command . parser . add_option ( cmdoptions . no_binary ( ) ) <nl> + pip_command . parser . add_option ( cmdoptions . only_binary ( ) ) <nl> + index_opts = cmdoptions . make_option_group ( <nl> + cmdoptions . index_group , <nl> pip_command . parser , <nl> ) <nl> pip_command . parser . insert_option_group ( 0 , index_opts ) <nl> mmm a / pipenv / patched / piptools / scripts / sync . py <nl> ppp b / pipenv / patched / piptools / scripts / sync . py <nl> <nl> import os <nl> import sys <nl> <nl> - import pip9 <nl> <nl> from . . import click , sync <nl> + from . . _compat import parse_requirements , get_installed_distributions <nl> from . . exceptions import PipToolsError <nl> from . . logging import log <nl> from . . utils import flat_map <nl> def cli ( dry_run , force , find_links , index_url , extra_index_url , no_index , quiet , <nl> log . error ( ' ERROR : ' + msg ) <nl> sys . exit ( 2 ) <nl> <nl> - requirements = flat_map ( lambda src : pip9 . req . parse_requirements ( src , session = True ) , <nl> + requirements = flat_map ( lambda src : parse_requirements ( src , session = True ) , <nl> src_files ) <nl> <nl> try : <nl> def cli ( dry_run , force , find_links , index_url , extra_index_url , no_index , quiet , <nl> log . error ( str ( e ) ) <nl> sys . exit ( 2 ) <nl> <nl> - installed_dists = pip9 . get_installed_distributions ( skip = [ ] , user_only = user_only ) <nl> + installed_dists = get_installed_distributions ( skip = [ ] , user_only = user_only ) <nl> to_install , to_uninstall = sync . diff ( requirements , installed_dists ) <nl> <nl> install_flags = [ ] <nl> mmm a / pipenv / patched / piptools / utils . py <nl> ppp b / pipenv / patched / piptools / utils . py <nl> <nl> from __future__ import ( absolute_import , division , print_function , <nl> unicode_literals ) <nl> <nl> + import os <nl> import sys <nl> from itertools import chain , groupby <nl> from collections import OrderedDict <nl> + from contextlib import contextmanager <nl> <nl> - from pip9 . req import InstallRequirement <nl> + from . _compat import InstallRequirement <nl> <nl> from first import first <nl> <nl> def fs_str ( string ) : <nl> <nl> <nl> _fs_encoding = sys . getfilesystemencoding ( ) or sys . getdefaultencoding ( ) <nl> + <nl> + <nl> + # Borrowed from pew to avoid importing pew which imports psutil <nl> + # See https : / / github . com / berdario / pew / blob / master / pew / _utils . py # L82 <nl> + @ contextmanager <nl> + def temp_environ ( ) : <nl> + "" "" "" Allow the ability to set os . environ temporarily "" "" "" <nl> + environ = dict ( os . environ ) <nl> + try : <nl> + yield <nl> + <nl> + finally : <nl> + os . environ . clear ( ) <nl> + os . environ . update ( environ ) <nl> mmm a / pipenv / patched / safety / cli . py <nl> ppp b / pipenv / patched / safety / cli . py <nl> <nl> from pip import get_installed_distributions <nl> except ImportError : <nl> # pip 10 <nl> - from pip9 . _internal . utils . misc import get_installed_distributions <nl> + from pip . _internal . utils . misc import get_installed_distributions <nl> <nl> <nl> @ click . group ( ) <nl> mmm a / tasks / vendoring / __init__ . py <nl> ppp b / tasks / vendoring / __init__ . py <nl> def vendor ( ctx , vendor_dir , rewrite = True ) : <nl> log ( ' Renaming specified libs . . . ' ) <nl> for item in vendor_dir . iterdir ( ) : <nl> if item . is_dir ( ) : <nl> - if item . name = = ' requests ' and not ( item / ' cacert . pem ' ) . exists ( ) : <nl> - if ' certifi ' in vendored_libs : <nl> - cert = vendor_dir / ' certifi ' / ' cacert . pem ' <nl> - copy_to = item / ' cacert . pem ' <nl> - copy_to . write_bytes ( cert . read_bytes ( ) ) <nl> if rewrite : <nl> log ( ' Rewriting imports for % s . . . ' % item ) <nl> rewrite_imports ( item , vendored_libs , vendor_dir ) <nl> mmm a / tasks / vendoring / patches / patched / _post - pip - update - imports . patch <nl> ppp b / tasks / vendoring / patches / patched / _post - pip - update - imports . patch <nl> DecodeError , ReadTimeoutError , ProtocolError , LocationParseError ) <nl> <nl> from io import UnsupportedOperation <nl> mmmmmm a / pipenv / patched / piptools / cache . py <nl> - ppp b / pipenv / patched / piptools / cache . py <nl> - import json <nl> - import os <nl> - import sys <nl> - <nl> - - from pip . _vendor . packaging . requirements import Requirement <nl> - + from pip9 . _vendor . packaging . requirements import Requirement <nl> - <nl> - from . exceptions import PipToolsError <nl> - from . locations import CACHE_DIR <nl> mmmmmm a / pipenv / patched / piptools / repositories / base . py <nl> - ppp b / pipenv / patched / piptools / repositories / base . py <nl> - class BaseRepository ( object ) : <nl> - @ contextmanager <nl> - def allow_all_wheels ( self ) : <nl> - "" "" "" <nl> - - Monkey patches pip . Wheel to allow wheels from all platforms and Python versions . <nl> - + Monkey patches pip9 . Wheel to allow wheels from all platforms and Python versions . <nl> - "" "" "" <nl> mmmmmm a / pipenv / patched / piptools / repositories / local . py <nl> - ppp b / pipenv / patched / piptools / repositories / local . py <nl> - from contextlib import contextmanager <nl> - <nl> - from piptools . utils import as_tuple , key_from_req , make_install_requirement <nl> - from . base import BaseRepository <nl> - - from pip . utils . hashes import FAVORITE_HASH <nl> - + from pip9 . utils . hashes import FAVORITE_HASH <nl> - <nl> - <nl> - def ireq_satisfied_by_existing_pin ( ireq , existing_pin ) : <nl> mmmmmm a / pipenv / patched / piptools / repositories / pypi . py <nl> - ppp b / pipenv / patched / piptools / repositories / pypi . py <nl> - class PyPIRepository ( BaseRepository ) : <nl> - @ contextmanager <nl> - def allow_all_wheels ( self ) : <nl> - "" "" "" <nl> - - Monkey patches pip . Wheel to allow wheels from all platforms and Python versions . <nl> - + Monkey patches pip9 . Wheel to allow wheels from all platforms and Python versions . <nl> - <nl> - This also saves the candidate cache and set a new one , or else the results from the <nl> - previous non - patched calls will interfere . <nl> mmmmmm a / pipenv / patched / piptools / resolver . py <nl> - ppp b / pipenv / patched / piptools / resolver . py <nl> - from itertools import chain , count <nl> - import os <nl> - <nl> - from first import first <nl> - - from pip . req import InstallRequirement <nl> - + from pip9 . req import InstallRequirement <nl> - <nl> - from . import click <nl> - from . cache import DependencyCache <nl> mmmmmm a / pipenv / patched / piptools / scripts / compile . py <nl> - ppp b / pipenv / patched / piptools / scripts / compile . py <nl> - def cli ( verbose , dry_run , pre , rebuild , find_links , index_url , extra_index_url , <nl> - <nl> - <nl> - def get_pip_command ( ) : <nl> - - # Use pip ' s parser for pip . conf management and defaults . <nl> - + # Use pip ' s parser for pip9 . conf management and defaults . <nl> - # General options ( find_links , index_url , extra_index_url , trusted_host , <nl> - - # and pre ) are defered to pip . <nl> - + # and pre ) are defered to pip9 . <nl> - pip_command = PipCommand ( ) <nl> - index_opts = pip9 . cmdoptions . make_option_group ( <nl> - pip9 . cmdoptions . index_group , <nl> mmmmmm a / pipenv / patched / safety / cli . py <nl> - ppp b / pipenv / patched / safety / cli . py <nl> - try : <nl> - from pip import get_installed_distributions <nl> - except ImportError : <nl> - # pip 10 <nl> - - from pip . _internal . utils . misc import get_installed_distributions <nl> - + from pip9 . _internal . utils . misc import get_installed_distributions <nl> - <nl> - <nl> - @ click . group ( ) <nl> mmm a / tasks / vendoring / patches / patched / piptools . patch <nl> ppp b / tasks / vendoring / patches / patched / piptools . patch <nl> <nl> - + mmm a / pipenv / patched / piptools / locations . py <nl> ppp b / pipenv / patched / piptools / locations . py <nl> import os <nl> from shutil import rmtree <nl> <nl> from . click import secho <nl> - - from pip . utils . appdirs import user_cache_dir <nl> + - from . _compat import user_cache_dir <nl> + # Patch by vphilippon 2017 - 11 - 22 : Use pipenv cache path . <nl> - + # from pip9 . utils . appdirs import user_cache_dir <nl> + + # from . _compat import user_cache_dir <nl> + from pipenv . environments import PIPENV_CACHE_DIR <nl> <nl> # The user_cache_dir helper comes straight from pip itself <nl> <nl> # NOTE <nl> # We used to store the cache dir under ~ / . pip - tools , which is not the <nl> mmmmmm a / pipenv / patched / piptools / repositories / pypi . py <nl> - ppp b / pipenv / patched / piptools / repositories / pypi . py <nl> - import os <nl> - from contextlib import contextmanager <nl> - from shutil import rmtree <nl> pppmmm a / piptools / repositories / pypi . py <nl> ppp + b / piptools / repositories / pypi . py <nl> + from . . _compat import ( <nl> + Wheel , <nl> + FAVORITE_HASH , <nl> + TemporaryDirectory , <nl> + - PyPI <nl> + + PyPI , <nl> + + InstallRequirement , <nl> + + SafeFileCache , <nl> + ) <nl> <nl> - - from pip . download import is_file_url , url_to_path <nl> - - from pip . index import PackageFinder <nl> - - from pip . req . req_set import RequirementSet <nl> - - from pip . wheel import Wheel <nl> - - from pip . utils . hashes import FAVORITE_HASH <nl> - + from notpip . download import is_file_url , url_to_path <nl> - + from notpip . index import PackageFinder <nl> - + from notpip . req . req_set import RequirementSet <nl> - + from notpip . wheel import Wheel <nl> - + from notpip . req . req_install import InstallRequirement <nl> + from pip9 . _vendor . packaging . requirements import InvalidRequirement <nl> + from pip9 . _vendor . pyparsing import ParseException <nl> - + from notpip . download import SafeFileCache <nl> - + from notpip . utils . hashes import FAVORITE_HASH <nl> - <nl> - from . . _compat import TemporaryDirectory <nl> + + <nl> from . . cache import CACHE_DIR <nl> + from pipenv . environments import PIPENV_CACHE_DIR <nl> from . . exceptions import NoCandidateFound <nl> from . . utils import ( fs_str , is_pinned_requirement , lookup_table , <nl> make_install_requirement ) <nl> - from . base import BaseRepository <nl> + except ImportError : <nl> + from pip . wheel import WheelCache <nl> <nl> <nl> + class HashCache ( SafeFileCache ) : <nl> + "" "" "" Caches hashes of PyPI artifacts so we do not need to re - download them <nl> + <nl> - + Hashes are only cached when the URL appears to contain a hash in it ( and the cache key includes <nl> - + the hash value returned from the server ) . This ought to avoid issues where the location on the <nl> + + Hashes are only cached when the URL appears to contain a hash in it and the cache key includes <nl> + + the hash value returned from the server ) . This ought to avoid ssues where the location on the <nl> + server changes . "" "" "" <nl> + def __init__ ( self , * args , * * kwargs ) : <nl> + session = kwargs . pop ( ' session ' ) <nl> + super ( HashCache , self ) . __init__ ( * args , * * kwargs ) <nl> + <nl> + def get_hash ( self , location ) : <nl> - + # if there is no location hash ( i . e . , md5 / sha256 / etc ) we don ' t want to store it <nl> + + # if there is no location hash ( i . e . , md5 / sha256 / etc ) we on ' t want to store it <nl> + hash_value = None <nl> + can_hash = location . hash <nl> + if can_hash : <nl> + <nl> + <nl> class PyPIRepository ( BaseRepository ) : <nl> - - DEFAULT_INDEX_URL = ' https : / / pypi . python . org / simple ' <nl> - + DEFAULT_INDEX_URL = ' https : / / pypi . org / simple ' <nl> + DEFAULT_INDEX_URL = PyPI . simple_url <nl> <nl> - class PyPIRepository ( BaseRepository ) : <nl> + class PyPIRepository ( BaseRepository ) : <nl> config ) , but any other PyPI mirror can be used if index_urls is <nl> changed / configured on the Finder . <nl> "" "" "" <nl> + def __init__ ( self , pip_options , session , use_json = False ) : <nl> self . session = session <nl> + self . use_json = use_json <nl> + self . pip_options = pip_options <nl> + - self . wheel_cache = WheelCache ( CACHE_DIR , pip_options . format_control ) <nl> + + self . wheel_cache = WheelCache ( PIPENV_CACHE_DIR , pip_options . format_control ) <nl> <nl> index_urls = [ pip_options . index_url ] + pip_options . extra_index_urls <nl> if pip_options . no_index : <nl> - class PyPIRepository ( BaseRepository ) : <nl> + class PyPIRepository ( BaseRepository ) : <nl> # of all secondary dependencies for the given requirement , so we <nl> # only have to go to disk once for each requirement <nl> self . _dependencies_cache = { } <nl> <nl> # Setup file paths <nl> self . freshen_build_caches ( ) <nl> - class PyPIRepository ( BaseRepository ) : <nl> + - self . _download_dir = fs_str ( os . path . join ( CACHE_DIR , ' pkgs ' ) ) <nl> + - self . _wheel_download_dir = fs_str ( os . path . join ( CACHE_DIR , ' wheels ' ) ) <nl> + + self . _download_dir = fs_str ( os . path . join ( PIPENV_CACHE_DIR , ' pkgs ' ) ) <nl> + + self . _wheel_download_dir = fs_str ( os . path . join ( PIPENV_CACHE_DIR , ' wheels ' ) ) <nl> + <nl> + def freshen_build_caches ( self ) : <nl> + "" "" "" <nl> + class PyPIRepository ( BaseRepository ) : <nl> best_candidate = max ( matching_candidates , key = self . finder . _candidate_sort_key ) <nl> <nl> # Turn the candidate into a pinned InstallRequirement <nl> + # TODO : Latest isn ' t always latest . <nl> + latest = list ( r . json ( ) [ ' releases ' ] . keys ( ) ) [ - 1 ] <nl> + if str ( ireq . req . specifier ) = = ' = = { 0 } ' . format ( latest ) : <nl> - + <nl> - + for requires in r . json ( ) . get ( ' info ' , { } ) . get ( ' requires_dist ' , { } ) : <nl> + + latest_url = ' https : / / pypi . org / pypi / { 0 } / { 1 } / json ' . format ( ireq . req . name , latest ) <nl> + + latest_requires = self . session . get ( latest_url ) <nl> + + for requires in latest_requires . json ( ) . get ( ' info ' , { } ) . get ( ' requires_dist ' , { } ) : <nl> + i = InstallRequirement . from_line ( requires ) <nl> + <nl> + if ' extra ' not in repr ( i . markers ) : <nl> + return set ( self . _json_dep_cache [ ireq ] ) <nl> + except Exception : <nl> + return set ( ) <nl> - + <nl> <nl> def get_dependencies ( self , ireq ) : <nl> + json_results = set ( ) <nl> "" "" "" <nl> Given a pinned or an editable InstallRequirement , returns a set of <nl> dependencies ( also InstallRequirements , but not necessarily pinned ) . <nl> - class PyPIRepository ( BaseRepository ) : <nl> + class PyPIRepository ( BaseRepository ) : <nl> if not ( ireq . editable or is_pinned_requirement ( ireq ) ) : <nl> raise TypeError ( ' Expected pinned or editable InstallRequirement , got { } ' . format ( ireq ) ) <nl> <nl> + ) <nl> + except TypeError : <nl> + pass <nl> - + <nl> + <nl> if ireq not in self . _dependencies_cache : <nl> if ireq . editable and ( ireq . source_dir and os . path . exists ( ireq . source_dir ) ) : <nl> # No download_dir for locally available editable requirements . <nl> - class PyPIRepository ( BaseRepository ) : <nl> - self . source_dir , <nl> - download_dir = download_dir , <nl> - wheel_download_dir = self . _wheel_download_dir , <nl> - - session = self . session ) <nl> - - self . _dependencies_cache [ ireq ] = reqset . _prepare_file ( self . finder , ireq ) <nl> - + session = self . session , <nl> - + ignore_installed = True , <nl> - + ignore_compatibility = False <nl> - + ) <nl> - + <nl> - + result = reqset . _prepare_file ( self . finder , ireq , ignore_requires_python = True ) <nl> - + <nl> + class PyPIRepository ( BaseRepository ) : <nl> + download_dir = download_dir , <nl> + wheel_download_dir = self . _wheel_download_dir , <nl> + session = self . session , <nl> + + ignore_installed = True , <nl> + + ignore_compatibility = False , <nl> + wheel_cache = self . wheel_cache , <nl> + ) <nl> + - self . _dependencies_cache [ ireq ] = reqset . _prepare_file ( <nl> + + result = reqset . _prepare_file ( <nl> + self . finder , <nl> + - ireq <nl> + + ireq , <nl> + + ignore_requires_python = True <nl> + ) <nl> + except TypeError : <nl> + # Pip > = 10 ( new resolver ! ) <nl> + class PyPIRepository ( BaseRepository ) : <nl> + isolated = False , <nl> + wheel_cache = self . wheel_cache , <nl> + use_user_site = False , <nl> + + ignore_compatibility = False <nl> + ) <nl> + self . resolver . resolve ( reqset ) <nl> + - self . _dependencies_cache [ ireq ] = reqset . requirements . values ( ) <nl> + + result = reqset . requirements . values ( ) <nl> + # Convert setup_requires dict into a somewhat usable form . <nl> + if setup_requires : <nl> + for section in setup_requires : <nl> + pass <nl> + <nl> + if reqset . requires_python : <nl> - + <nl> + marker = ' python_version = = "" { 0 } "" ' . format ( reqset . requires_python . replace ( ' ' , ' ' ) ) <nl> + new_req = InstallRequirement . from_line ( ' { 0 } ; { 1 } ' . format ( str ( ireq . req ) , marker ) ) <nl> + result = [ new_req ] <nl> + <nl> + self . _dependencies_cache [ ireq ] = result <nl> + reqset . cleanup_files ( ) <nl> return set ( self . _dependencies_cache [ ireq ] ) <nl> <nl> - def get_hashes ( self , ireq ) : <nl> - class PyPIRepository ( BaseRepository ) : <nl> + class PyPIRepository ( BaseRepository ) : <nl> matching_candidates = candidates_by_version [ matching_versions [ 0 ] ] <nl> <nl> return { <nl> @ contextmanager <nl> def allow_all_wheels ( self ) : <nl> "" "" "" <nl> - def open_local_or_remote_file ( link , session ) : <nl> - "" "" "" <nl> - Open local or remote file for reading . <nl> - <nl> - - : type link : pip . index . Link <nl> - + : type link : pip9 . index . Link <nl> - : type session : requests . Session <nl> - : raises ValueError : If link points to a local directory . <nl> - : return : a context manager to the opened file - like object <nl> - + mmm a / pipenv / patched / piptools / resolver . py <nl> ppp b / pipenv / patched / piptools / resolver . py <nl> from . import click <nl> elif not is_pinned_requirement ( ireq ) : <nl> raise TypeError ( ' Expected pinned or editable requirement , got { } ' . format ( ireq ) ) <nl> <nl> - class Resolver ( object ) : <nl> + class Resolver ( object ) : <nl> if ireq not in self . dependency_cache : <nl> log . debug ( ' { } not in cache , need to check index ' . format ( format_requirement ( ireq ) ) , fg = ' yellow ' ) <nl> dependencies = self . repository . get_dependencies ( ireq ) <nl> dependency_strings = self . dependency_cache [ ireq ] <nl> log . debug ( ' { : 25 } requires { } ' . format ( format_requirement ( ireq ) , <nl> ' , ' . join ( sorted ( dependency_strings , key = lambda s : s . lower ( ) ) ) or ' - ' ) ) <nl> - + from notpip . _vendor . packaging . markers import InvalidMarker <nl> + + from pip9 . _vendor . packaging . markers import InvalidMarker <nl> for dependency_string in dependency_strings : <nl> - yield InstallRequirement . from_line ( dependency_string , constraint = ireq . constraint ) <nl> + try : <nl> + yield InstallRequirement . from_line ( _dependency_string , constraint = ireq . constraint ) <nl> + except InvalidMarker : <nl> + yield InstallRequirement . from_line ( dependency_string , constraint = ireq . constraint ) <nl> - + <nl> <nl> def reverse_dependencies ( self , ireqs ) : <nl> non_editable = [ ireq for ireq in ireqs if not ireq . editable ] <nl> mmmmmm a / pipenv / patched / piptools / scripts / compile . py <nl> - ppp b / pipenv / patched / piptools / scripts / compile . py <nl> - import os <nl> - import sys <nl> - import tempfile <nl> - <nl> - - import pip <nl> - - from pip . req import InstallRequirement , parse_requirements <nl> - + import pip9 <nl> - + from pip9 . req import InstallRequirement , parse_requirements <nl> - <nl> - from . . import click <nl> - from . . exceptions import PipToolsError <nl> - from . . writer import OutputWriter <nl> - DEFAULT_REQUIREMENTS_FILE = ' requirements . in ' <nl> - <nl> - <nl> - - class PipCommand ( pip . basecommand . Command ) : <nl> - + class PipCommand ( pip9 . basecommand . Command ) : <nl> - name = ' PipCommand ' <nl> - <nl> - <nl> - def get_pip_command ( ) : <nl> - # General options ( find_links , index_url , extra_index_url , trusted_host , <nl> - # and pre ) are defered to pip . <nl> - pip_command = PipCommand ( ) <nl> - - index_opts = pip . cmdoptions . make_option_group ( <nl> - - pip . cmdoptions . index_group , <nl> - + index_opts = pip9 . cmdoptions . make_option_group ( <nl> - + pip9 . cmdoptions . index_group , <nl> - pip_command . parser , <nl> - ) <nl> - pip_command . parser . insert_option_group ( 0 , index_opts ) <nl> mmmmmm a / pipenv / patched / piptools / scripts / sync . py <nl> - ppp b / pipenv / patched / piptools / scripts / sync . py <nl> - from __future__ import ( absolute_import , division , print_function , <nl> - import os <nl> - import sys <nl> - <nl> - - import pip <nl> - + import pip9 <nl> - <nl> - from . . import click , sync <nl> - from . . exceptions import PipToolsError <nl> - def cli ( dry_run , force , find_links , index_url , extra_index_url , no_index , quiet , <nl> - log . error ( ' ERROR : ' + msg ) <nl> - sys . exit ( 2 ) <nl> - <nl> - - requirements = flat_map ( lambda src : pip . req . parse_requirements ( src , session = True ) , <nl> - + requirements = flat_map ( lambda src : pip9 . req . parse_requirements ( src , session = True ) , <nl> - src_files ) <nl> - <nl> - try : <nl> - def cli ( dry_run , force , find_links , index_url , extra_index_url , no_index , quiet , <nl> - log . error ( str ( e ) ) <nl> - sys . exit ( 2 ) <nl> - <nl> - - installed_dists = pip . get_installed_distributions ( skip = [ ] , user_only = user_only ) <nl> - + installed_dists = pip9 . get_installed_distributions ( skip = [ ] , user_only = user_only ) <nl> - to_install , to_uninstall = sync . diff ( requirements , installed_dists ) <nl> - <nl> - install_flags = [ ] <nl> - + mmm a / pipenv / patched / piptools / utils . py <nl> ppp b / pipenv / patched / piptools / utils . py <nl> - import sys <nl> - from itertools import chain , groupby <nl> - from collections import OrderedDict <nl> - <nl> - - from pip . req import InstallRequirement <nl> - + from pip9 . req import InstallRequirement <nl> - <nl> - from first import first <nl> - <nl> - def comment ( text ) : <nl> + def comment ( text ) : <nl> return style ( text , fg = ' green ' ) <nl> <nl> <nl> <nl> <nl> def format_requirement ( ireq , marker = None ) : <nl> - def format_requirement ( ireq , marker = None ) : <nl> + def format_requirement ( ireq , marker = None ) : <nl> line = str ( ireq . req ) . lower ( ) <nl> <nl> if marker : <nl> <nl> return line <nl> <nl> - <nl> pppmmm a / piptools / _compat / pip_compat . py <nl> ppp + b / piptools / _compat / pip_compat . py <nl> + <nl> + # - * - coding = utf - 8 - * - <nl> + import importlib <nl> + <nl> + - def do_import ( module_path , subimport = None , old_path = None ) : <nl> + + <nl> + + def do_import ( module_path , subimport = None , old_path = None , vendored_name = None ) : <nl> + internal = ' pip . _internal . { 0 } ' . format ( module_path ) <nl> + old_path = old_path or module_path <nl> + pip9 = ' pip . { 0 } ' . format ( old_path ) <nl> + - try : <nl> + - _tmp = importlib . import_module ( internal ) <nl> + - except ImportError : <nl> + - _tmp = importlib . import_module ( pip9 ) <nl> + + _tmp = None <nl> + + if vendored_name : <nl> + + vendor = ' { 0 } . { 1 } ' . format ( vendored_name , old_path ) <nl> + + try : <nl> + + _tmp = importlib . import_module ( vendor ) <nl> + + except ImportError : <nl> + + pass <nl> + + if not _tmp : <nl> + + try : <nl> + + _tmp = importlib . import_module ( internal ) <nl> + + except ImportError : <nl> + + _tmp = importlib . import_module ( pip9 ) <nl> + if subimport : <nl> + return getattr ( _tmp , subimport , _tmp ) <nl> + return _tmp <nl> + <nl> + <nl> + - InstallRequirement = do_import ( ' req . req_install ' , ' InstallRequirement ' ) <nl> + - parse_requirements = do_import ( ' req . req_file ' , ' parse_requirements ' ) <nl> + - RequirementSet = do_import ( ' req . req_set ' , ' RequirementSet ' ) <nl> + - user_cache_dir = do_import ( ' utils . appdirs ' , ' user_cache_dir ' ) <nl> + - FAVORITE_HASH = do_import ( ' utils . hashes ' , ' FAVORITE_HASH ' ) <nl> + - is_file_url = do_import ( ' download ' , ' is_file_url ' ) <nl> + - url_to_path = do_import ( ' download ' , ' url_to_path ' ) <nl> + - PackageFinder = do_import ( ' index ' , ' PackageFinder ' ) <nl> + - FormatControl = do_import ( ' index ' , ' FormatControl ' ) <nl> + - Wheel = do_import ( ' wheel ' , ' Wheel ' ) <nl> + - Command = do_import ( ' basecommand ' , ' Command ' ) <nl> + - cmdoptions = do_import ( ' cmdoptions ' ) <nl> + - get_installed_distributions = do_import ( ' utils . misc ' , ' get_installed_distributions ' , old_path = ' utils ' ) <nl> + - PyPI = do_import ( ' models . index ' , ' PyPI ' ) <nl> + + InstallRequirement = do_import ( ' req . req_install ' , ' InstallRequirement ' , vendored_name = ' notpip ' ) <nl> + + parse_requirements = do_import ( ' req . req_file ' , ' parse_requirements ' , vendored_name = ' notpip ' ) <nl> + + RequirementSet = do_import ( ' req . req_set ' , ' RequirementSet ' , vendored_name = ' notpip ' ) <nl> + + user_cache_dir = do_import ( ' utils . appdirs ' , ' user_cache_dir ' , vendored_name = ' notpip ' ) <nl> + + FAVORITE_HASH = do_import ( ' utils . hashes ' , ' FAVORITE_HASH ' , vendored_name = ' notpip ' ) <nl> + + is_file_url = do_import ( ' download ' , ' is_file_url ' , vendored_name = ' notpip ' ) <nl> + + url_to_path = do_import ( ' download ' , ' url_to_path ' , vendored_name = ' notpip ' ) <nl> + + PackageFinder = do_import ( ' index ' , ' PackageFinder ' , vendored_name = ' notpip ' ) <nl> + + FormatControl = do_import ( ' index ' , ' FormatControl ' , vendored_name = ' notpip ' ) <nl> + + Wheel = do_import ( ' wheel ' , ' Wheel ' , vendored_name = ' notpip ' ) <nl> + + Command = do_import ( ' basecommand ' , ' Command ' , vendored_name = ' pip9 ' ) <nl> + + cmdoptions = do_import ( ' cmdoptions ' , vendored_name = ' pip9 ' ) <nl> + + get_installed_distributions = do_import ( ' utils . misc ' , ' get_installed_distributions ' , old_path = ' utils ' , vendored_name = ' pip9 ' ) <nl> + + PyPI = do_import ( ' models . index ' , ' PyPI ' , vendored_name = ' notpip ' ) <nl> + + SafeFileCache = do_import ( ' download ' , ' SafeFileCache ' , vendored_name = ' notpip ' ) <nl> pppmmm a / pipenv / patched / piptools / _compat / __init__ . py <nl> ppp + b / pipenv / patched / piptools / _compat / __init__ . py <nl> + from . pip_compat import ( <nl> + cmdoptions , <nl> + get_installed_distributions , <nl> + PyPI , <nl> + + SafeFileCache , <nl> + ) <nl> mmm a / tasks / vendoring / patches / vendor / pip . patch <nl> ppp b / tasks / vendoring / patches / vendor / pip . patch <nl> path_to_url ( wheel_file ) ) <nl> assert req . link . is_wheel <nl> # extract the wheel into the dir <nl> + <nl> pppmmm a / pipenv / vendor / pip9 / __main__ . py <nl> ppp + b / pipenv / vendor / pip9 / __main__ . py <nl> + if __package__ = = ' ' : <nl> + import pip9 # noqa <nl> + <nl> + if __name__ = = ' __main__ ' : <nl> + - sys . exit ( pip . main ( ) ) <nl> + + sys . exit ( pip9 . main ( ) ) <nl> mmm a / tests / integration / test_install_markers . py <nl> ppp b / tests / integration / test_install_markers . py <nl> def test_environment_variable_value_does_not_change_hash ( PipenvInstance , pypi ) : <nl> with open ( p . pipfile_path , ' w ' ) as f : <nl> f . write ( "" "" "" <nl> [ [ source ] ] <nl> - url = ' https : / / $ { PYPI_USERNAME } : $ { PYPI_PASSWORD } @ pypi . python . org / simple ' <nl> + url = ' https : / / $ { PYPI_USERNAME } : $ { PYPI_PASSWORD } @ pypi . org / simple ' <nl> verify_ssl = true <nl> name = ' pypi ' <nl> [ requires ] <nl> mmm a / tests / integration / test_install_uri . py <nl> ppp b / tests / integration / test_install_uri . py <nl> def test_install_named_index_alias ( PipenvInstance , pypi ) : <nl> with open ( p . pipfile_path , ' w ' ) as f : <nl> contents = "" "" "" <nl> [ [ source ] ] <nl> - url = "" https : / / pypi . python . org / simple "" <nl> + url = "" https : / / pypi . org / simple "" <nl> verify_ssl = true <nl> name = "" pypi "" <nl> <nl> mmm a / tests / integration / test_lock . py <nl> ppp b / tests / integration / test_lock . py <nl> def test_private_index_skip_lock ( PipenvInstance ) : <nl> with open ( p . pipfile_path , ' w ' ) as f : <nl> contents = "" "" "" <nl> [ [ source ] ] <nl> - url = "" https : / / pypi . python . org / simple "" <nl> + url = "" https : / / pypi . org / simple "" <nl> verify_ssl = true <nl> name = "" pypi "" <nl> <nl> def test_private_index_lock_requirements ( PipenvInstance ) : <nl> with open ( p . pipfile_path , ' w ' ) as f : <nl> contents = "" "" "" <nl> [ [ source ] ] <nl> - url = "" https : / / pypi . python . org / simple "" <nl> + url = "" https : / / pypi . org / simple "" <nl> verify_ssl = true <nl> name = "" pypi "" <nl> <nl> def test_private_index_lock_requirements ( PipenvInstance ) : <nl> assert c . return_code = = 0 <nl> c = p . pipenv ( ' lock - r ' ) <nl> assert c . return_code = = 0 <nl> - assert ' - i https : / / pypi . python . org / simple ' in c . out . strip ( ) <nl> + assert ' - i https : / / pypi . org / simple ' in c . out . strip ( ) <nl> assert ' - - extra - index - url https : / / test . pypi . org / simple ' in c . out . strip ( ) <nl> <nl> <nl> mmm a / tests / integration / test_project . py <nl> ppp b / tests / integration / test_project . py <nl> def test_get_source ( PipenvInstance , pypi , lock_first ) : <nl> name = "" testindex "" <nl> <nl> [ [ source ] ] <nl> - url = "" https : / / pypi . python . org / simple "" <nl> + url = "" https : / / pypi . org / simple "" <nl> verify_ssl = "" true "" <nl> name = "" pypi "" <nl> <nl> def test_get_source ( PipenvInstance , pypi , lock_first ) : <nl> assert c . return_code = = 0 <nl> project = Project ( ) <nl> sources = [ <nl> - [ ' pypi ' , ' https : / / pypi . python . org / simple ' ] , <nl> + [ ' pypi ' , ' https : / / pypi . org / simple ' ] , <nl> [ ' testindex ' , os . environ . get ( ' PIPENV_TEST_INDEX ' ) ] <nl> ] <nl> for src in sources : <nl> mmm a / tests / pytest - pypi / Pipfile <nl> ppp b / tests / pytest - pypi / Pipfile <nl> <nl> [ [ source ] ] <nl> <nl> - url = "" https : / / pypi . python . org / simple "" <nl> + url = "" https : / / pypi . org / simple "" <nl> verify_ssl = true <nl> name = "" pypi "" <nl> <nl> mmm a / tests / pytest - pypi / Pipfile . lock <nl> ppp b / tests / pytest - pypi / Pipfile . lock <nl> <nl> "" sources "" : [ <nl> { <nl> "" name "" : "" pypi "" , <nl> - "" url "" : "" https : / / pypi . python . org / simple "" , <nl> + "" url "" : "" https : / / pypi . org / simple "" , <nl> "" verify_ssl "" : true <nl> } <nl> ] <nl> mmm a / tests / unit / test_utils . py <nl> ppp b / tests / unit / test_utils . py <nl> def test_get_requirements ( self ) : <nl> ( [ { ' url ' : ' https : / / test . example . com / simple ' , ' verify_ssl ' : False } ] , <nl> [ ' - i ' , ' https : / / test . example . com / simple ' , ' - - trusted - host ' , ' test . example . com ' ] ) , <nl> <nl> - ( [ { ' url ' : "" https : / / pypi . python . org / simple "" } , <nl> + ( [ { ' url ' : "" https : / / pypi . org / simple "" } , <nl> { ' url ' : "" https : / / custom . example . com / simple "" } ] , <nl> - [ ' - i ' , ' https : / / pypi . python . org / simple ' , <nl> + [ ' - i ' , ' https : / / pypi . org / simple ' , <nl> ' - - extra - index - url ' , ' https : / / custom . example . com / simple ' ] ) , <nl> <nl> - ( [ { ' url ' : "" https : / / pypi . python . org / simple "" } , <nl> + ( [ { ' url ' : "" https : / / pypi . org / simple "" } , <nl> { ' url ' : "" https : / / custom . example . com / simple "" , ' verify_ssl ' : False } ] , <nl> - [ ' - i ' , ' https : / / pypi . python . org / simple ' , <nl> + [ ' - i ' , ' https : / / pypi . org / simple ' , <nl> ' - - extra - index - url ' , ' https : / / custom . example . com / simple ' , <nl> ' - - trusted - host ' , ' custom . example . com ' ] ) , <nl> <nl> - ( [ { ' url ' : "" https : / / pypi . python . org / simple "" } , <nl> + ( [ { ' url ' : "" https : / / pypi . org / simple "" } , <nl> { ' url ' : "" https : / / user : password @ custom . example . com / simple "" , ' verify_ssl ' : False } ] , <nl> - [ ' - i ' , ' https : / / pypi . python . org / simple ' , <nl> + [ ' - i ' , ' https : / / pypi . org / simple ' , <nl> ' - - extra - index - url ' , ' https : / / user : password @ custom . example . com / simple ' , <nl> ' - - trusted - host ' , ' custom . example . com ' ] ) , <nl> <nl> - ( [ { ' url ' : "" https : / / pypi . python . org / simple "" } , <nl> + ( [ { ' url ' : "" https : / / pypi . org / simple "" } , <nl> { ' url ' : "" https : / / user : password @ custom . example . com / simple "" , } ] , <nl> - [ ' - i ' , ' https : / / pypi . python . org / simple ' , <nl> + [ ' - i ' , ' https : / / pypi . org / simple ' , <nl> ' - - extra - index - url ' , ' https : / / user : password @ custom . example . com / simple ' , ] ) , <nl> ] , <nl> ) <nl>",Merge pull request from pypa / update - piptools,pypa/pipenv,a250ff70ebb86a2aecedc0dea51a553749bedc7c,2018-05-23T21:51:30Z
"mmm a / bokeh / pluginutils . py <nl> ppp b / bokeh / pluginutils . py <nl> def wrapper ( * args , * * kwargs ) : <nl> <nl> obj = func ( * args , * * kwargs ) <nl> tag = embed . autoload_server ( obj , session ) <nl> - obj . tag = tag <nl> + obj . _tag = tag <nl> <nl> curdoc ( ) . add ( obj ) <nl> changed = session . store_document ( curdoc ( ) ) <nl> mmm a / examples / app / stock_applet / stock_app . py <nl> ppp b / examples / app / stock_applet / stock_app . py <nl> def __init__ ( self , * args , * * kwargs ) : <nl> super ( StockApp , self ) . __init__ ( * args , * * kwargs ) <nl> self . _dfs = { } <nl> <nl> + @ property <nl> + def tag ( self ) : <nl> + return self . _tag <nl> + <nl> @ classmethod <nl> def create ( cls ) : <nl> "" "" "" <nl>",fix issue with app broken due to HasProps not allowing to set arbitrary public members anymore,bokeh/bokeh,6da9801c393dde5452be769ba09367694304d427,2014-12-04T10:14:17Z
"mmm a / docs / docsite / rst / roadmap / ROADMAP_2_2 . rst <nl> ppp b / docs / docsite / rst / roadmap / ROADMAP_2_2 . rst <nl> Lead by Nate C , Peter S <nl> <nl> Role revamp <nl> mmmmmmmmm - - <nl> - - * * Implement ‘ role revamp ’ proposal to give users more control on role / task execution ( Brian ) * * <nl> + - Implement ‘ role revamp ’ proposal to give users more control on role / task execution ( Brian ) <nl> <nl> - * * https : / / github . com / ansible / proposals / blob / master / roles_revamp . md * * <nl> <nl>",rst validation fix ( ),ansible/ansible,7f8aaf97dea659523637d9cce2d840535f9da785,2017-08-03T14:07:46Z
"mmm a / Changelog <nl> ppp b / Changelog <nl> <nl> <nl> If you ' re looking for versions prior to 3 . 0 . x you should go to : ref : ` history ` . <nl> <nl> + . . _version - 3 . 0 . 18 : <nl> + <nl> + 3 . 0 . 18 <nl> + = = = = = = <nl> + : release - date : 2013 - 04 - 09 04 : 00 : 00 P . M BST <nl> + <nl> + - Now depends on : mod : ` billiard ` 2 . 7 . 3 . 25 . <nl> + <nl> + - Now depends on : mod : ` kombu ` 2 . 5 . 9 . <nl> + <nl> + - Worker / statedb : Now uses pickle protocol 2 ( Py2 . 5 + ) <nl> + <nl> + - : class : ` ~ celery . app . utils . ConfigurationView ` is now a ` ` MutableMapping ` ` . <nl> + <nl> + Contributed by Aaron Harnly . <nl> + <nl> + - Fixed memory leak in LRU cache implementation . <nl> + <nl> + Fix contributed by Romuald Brunet . <nl> + <nl> + - ` ` celery . contrib . rdb ` ` : Now works when sockets are in non - blocking mode . <nl> + <nl> + Fix contributed by Theo Spears . <nl> + <nl> + - Canvas list operations now takes application instance from the first <nl> + task in the list , instead of depending on the ` ` current_app ` ` ( Issue # 1249 ) . <nl> + <nl> + <nl> . . _version - 3 . 0 . 17 : <nl> <nl> 3 . 0 . 17 <nl>",Updates Changelog,celery/celery,a02835b2170305bc61bf5985d4c9d3d2c1f632e0,2013-04-09T12:58:49Z
"mmm a / spacy / cli / train . py <nl> ppp b / spacy / cli / train . py <nl> def train ( cmd , lang , output_dir , train_data , dev_data , n_iter = 10 , n_sents = 0 , <nl> # starts high and decays sharply , to force the optimizer to explore . <nl> # Batch size starts at 1 and grows , so that we make updates quickly <nl> # at the beginning of training . <nl> - dropout_rates = util . decaying ( util . env_opt ( ' dropout_from ' , 0 . 6 ) , <nl> - util . env_opt ( ' dropout_to ' , 0 . 1 ) , <nl> - util . env_opt ( ' dropout_decay ' , 1e - 5 ) ) <nl> + dropout_rates = util . decaying ( util . env_opt ( ' dropout_from ' , 0 . 2 ) , <nl> + util . env_opt ( ' dropout_to ' , 0 . 2 ) , <nl> + util . env_opt ( ' dropout_decay ' , 0 . 0 ) ) <nl> batch_sizes = util . compounding ( util . env_opt ( ' batch_from ' , 1 ) , <nl> - util . env_opt ( ' batch_to ' , 4 ) , <nl> + util . env_opt ( ' batch_to ' , 16 ) , <nl> util . env_opt ( ' batch_compound ' , 1 . 001 ) ) <nl> corpus = GoldCorpus ( train_path , dev_path , limit = n_sents ) <nl> n_train_words = corpus . count_train ( ) <nl>",Update defaults,explosion/spaCy,be4f0b64605b036f06fdd919253b719fdc88b5bb,2017-10-08T07:08:12Z
"mmm a / lib / matplotlib / backends / backend_agg . py <nl> ppp b / lib / matplotlib / backends / backend_agg . py <nl> def print_jpg ( self , filename_or_obj , * args , dryrun = False , pil_kwargs = None , <nl> the JPEG compression algorithm , and results in large files <nl> with hardly any gain in image quality . This parameter is <nl> deprecated . <nl> - <nl> optimize : bool , default : False <nl> Whether the encoder should make an extra pass over the image <nl> in order to select optimal encoder settings . This parameter is <nl> deprecated . <nl> - <nl> progressive : bool , default : False <nl> Whether the image should be stored as a progressive JPEG file . <nl> This parameter is deprecated . <nl> - <nl> pil_kwargs : dict , optional <nl> Additional keyword arguments that are passed to <nl> ` PIL . Image . Image . save ` when saving the figure . These take <nl> mmm a / lib / matplotlib / backends / backend_mixed . py <nl> ppp b / lib / matplotlib / backends / backend_mixed . py <nl> def __init__ ( self , figure , width , height , dpi , vector_renderer , <nl> mmmmmmmmm - <nl> figure : ` matplotlib . figure . Figure ` <nl> The figure instance . <nl> - <nl> width : scalar <nl> The width of the canvas in logical units <nl> - <nl> height : scalar <nl> The height of the canvas in logical units <nl> - <nl> dpi : float <nl> The dpi of the canvas <nl> - <nl> vector_renderer : ` matplotlib . backend_bases . RendererBase ` <nl> An instance of a subclass of <nl> ` ~ matplotlib . backend_bases . RendererBase ` that will be used for the <nl> vector drawing . <nl> - <nl> raster_renderer_class : ` matplotlib . backend_bases . RendererBase ` <nl> The renderer class to use for the raster drawing . If not provided , <nl> this will use the Agg backend ( which is currently the only viable <nl> mmm a / lib / matplotlib / backends / backend_pdf . py <nl> ppp b / lib / matplotlib / backends / backend_pdf . py <nl> def _create_pdf_info_dict ( backend , metadata ) : <nl> mmmmmmmmm - <nl> backend : str <nl> The name of the backend to use in the Producer value . <nl> + <nl> metadata : Dict [ str , Union [ str , datetime , Name ] ] <nl> A dictionary of metadata supplied by the user with information <nl> following the PDF specification , also defined in <nl> def __init__ ( self , id , len , file , extra = None , png = None ) : <nl> "" "" "" <nl> Parameters <nl> mmmmmmmmm - <nl> - <nl> id : int <nl> Object id of the stream . <nl> len : Reference or None <nl> def __init__ ( self , filename , metadata = None ) : <nl> "" "" "" <nl> Parameters <nl> mmmmmmmmm - <nl> - <nl> filename : str or path - like or file - like <nl> Output target ; if a string , a file will be opened for writing . <nl> + <nl> metadata : dict from strings to strings and dates <nl> Information dictionary object ( see PDF reference section 10 . 2 . 1 <nl> ' Document Information Dictionary ' ) , e . g . : <nl> def __init__ ( self , filename , keep_empty = True , metadata = None ) : <nl> Plots using ` PdfPages . savefig ` will be written to a file at this <nl> location . The file is opened at once and any older file with the <nl> same name is overwritten . <nl> + <nl> keep_empty : bool , optional <nl> If set to False , then empty pdf files will be deleted automatically <nl> when closed . <nl> + <nl> metadata : dict , optional <nl> Information dictionary object ( see PDF reference section 10 . 2 . 1 <nl> ' Document Information Dictionary ' ) , e . g . : <nl> mmm a / lib / matplotlib / backends / backend_pgf . py <nl> ppp b / lib / matplotlib / backends / backend_pgf . py <nl> def __init__ ( self , filename , * , keep_empty = True , metadata = None ) : <nl> filename : str or path - like <nl> Plots using ` PdfPages . savefig ` will be written to a file at this <nl> location . Any older file with the same name is overwritten . <nl> + <nl> keep_empty : bool , default : True <nl> If set to False , then empty pdf files will be deleted automatically <nl> when closed . <nl> + <nl> metadata : dict , optional <nl> Information dictionary object ( see PDF reference section 10 . 2 . 1 <nl> ' Document Information Dictionary ' ) , e . g . : <nl> mmm a / lib / matplotlib / backends / backend_svg . py <nl> ppp b / lib / matplotlib / backends / backend_svg . py <nl> def end ( self , tag = None , indent = True ) : <nl> tag <nl> Element tag . If given , the tag must match the start tag . If <nl> omitted , the current element is closed . <nl> - "" "" "" <nl> + "" "" "" <nl> if tag : <nl> assert self . __tags , "" unbalanced end ( % s ) "" % tag <nl> assert escape_cdata ( tag ) = = self . __tags [ - 1 ] , \ <nl> def _draw_text_as_path ( self , gc , x , y , s , prop , angle , ismath , mtext = None ) : <nl> Parameters <nl> mmmmmmmmm - <nl> s : str <nl> - text to be converted <nl> + text to be converted <nl> prop : ` matplotlib . font_manager . FontProperties ` <nl> - font property <nl> + font property <nl> ismath : bool <nl> - If True , use mathtext parser . If "" TeX "" , use * usetex * mode . <nl> + If True , use mathtext parser . If "" TeX "" , use * usetex * mode . <nl> "" "" "" <nl> writer = self . writer <nl> <nl> def print_svg ( self , filename , * args , * * kwargs ) : <nl> mmmmmmmmm - <nl> filename : str or path - like or file - like <nl> Output target ; if a string , a file will be opened for writing . <nl> + <nl> metadata : Dict [ str , Any ] , optional <nl> Metadata in the SVG file defined as key - value pairs of strings , <nl> datetimes , or lists of strings , e . g . , ` ` { ' Creator ' : ' My software ' , <nl> mmm a / lib / matplotlib / backends / qt_editor / _formlayout . py <nl> ppp b / lib / matplotlib / backends / qt_editor / _formlayout . py <nl> def __init__ ( self , data , comment = "" "" , with_margin = False , parent = None ) : <nl> data : list of ( label , value ) pairs <nl> The data to be edited in the form . <nl> comment : str , optional <nl> - <nl> with_margin : bool , default : False <nl> If False , the form elements reach to the border of the widget . <nl> This is the desired behavior if the FormWidget is used as a widget <nl>",Merge pull request from Carreau / velin - II,matplotlib/matplotlib,104843052a927dbb34ec3b8a2463da0767161c3d,2020-08-18T16:00:15Z
"mmm a / build_tools / travis / install . sh <nl> ppp b / build_tools / travis / install . sh <nl> except ImportError : <nl> fi <nl> <nl> if [ [ "" $ RUN_FLAKE8 "" = = "" true "" ] ] ; then <nl> - # flake8 version is temporarily set to 2 . 5 . 1 because the next <nl> - # version available on conda ( 3 . 3 . 0 ) has a bug that checks non <nl> - # python files and cause non meaningful flake8 errors <nl> - conda install - - yes flake8 = 2 . 5 . 1 <nl> + # flake8 3 . 5 only available from pip at the time of writing ( 2017 - 11 - 08 ) <nl> + # bug fixed in flake8 3 . 5 is https : / / gitlab . com / pycqa / flake8 / issues / 362 <nl> + pip install flake8 <nl> fi <nl>",TRAVIS install flake8 3 . 5 from pip ( ),scikit-learn/scikit-learn,3fa7a06bff319adf3a234c5b78ab78843afece2a,2017-11-08T13:34:49Z
